Script started on 2025-11-16 12:17:28+00:00 [TERM="xterm-256color" TTY="/dev/pts/0" COLUMNS="111" LINES="39"]
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cd ..
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ cd ..mlflow server   --backend-store-uri sqlite:////home/$USER/mlflow.db   --default-artifact-root gs://mlopsga1_data/week5/mlflow-artifacts   --host 0.0.0.0   --port 800050008000[A[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ cd ..[K
[K
[K[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[7mls -ld week8[27mls -ld week8
[?2004ldrwxr-xr-x 3 satishsharma1911_gmail_com satishsharma1911_gmail_com 4096 Nov 16 12:17 [0m[01;34mweek8[0m
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ [7mcp ../week5/mlflow_test.p[27m[7my[27m[7m week8/      [27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ cp ../week5/mlflow_test.py week8/      
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ [7mcp ../week5/README-week5.[27m[7mm[27m[7md week8/[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ cp ../week5/README-week5.md week8/
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ [7mcp -r mlruns week8/mlruns[27m[7m_[27m[7mcopy[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ cp -r mlruns week8/mlruns_copy
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ [7mls -ahl week8[27mls -ahl week8
[?2004ltotal 28K
drwxr-xr-x  4 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:18 [0m[01;34m.[0m
drwxr-xr-x 13 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:10 [01;34m..[0m
drwxr-xr-x  8 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:17 [01;34m.git[0m
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com  559 Nov 16 12:18 README-week5.md
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 3.2K Nov 16 12:13 README.md
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 1021 Nov 16 12:18 mlflow_test.py
drwxr-xr-x  5 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:18 [01;34mmlruns_copy[0m
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com    0 Nov 16 12:17 myscript.txt
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops[00m$ [7mcd week8[27mcd week8
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mnano iris_poisoning[27m[7m_[27m[7mmlflow.py[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ nano iris_poisoning_mlflow.py
[?2004l[?2004h[?1049h[22;0;0t[1;39r(B[m[4l[?7h[39;49m[?1h=[?1h=[?25l[39;49m(B[m[H[2J[37;50H(B[0;7m[ New File ](B[m[H(B[0;7m  GNU nano 5.4                                iris_poisoning_mlflow.py                                         [1;110H(B[m[38d(B[0;7m^G(B[m Help[38;16H(B[0;7m^O(B[m Write Out   (B[0;7m^W(B[m Where Is    (B[0;7m^K(B[m Cut[38;61H(B[0;7m^T(B[m Execute     (B[0;7m^C(B[m Location    (B[0;7mM-U(B[m Undo[39d(B[0;7m^X(B[m Exit[39;16H(B[0;7m^R(B[m Read File   (B[0;7m^\(B[m Replace     (B[0;7m^U(B[m Paste[61G(B[0;7m^J(B[m Justify     (B[0;7m^_(B[m Go To Line  (B[0;7mM-E(B[m Redo[2d[?12l[?25h[?25l[1;72H(B[0;7m*[37d(B[m[K[1;110H[2;9Hrun_dir = os.path.join((B[0;1m[32m"mlruns"[39m(B[m, exp_id, run_id, (B[0;1m[32m"artifacts"[39m(B[m)[3;9Hos.makedirs(run_dir, exist_ok=(B[0;1m[35mTrue[39m(B[m)[4;9Hcm_path = plot_and_save_cm(y_test, y_pred, run_dir, f(B[0;1m[32m"{int(poison_fraction*100)}pct"[39m(B[m)[5;9Hmlflow.log_artifact(cm_path)[6;9Hjoblib.dump(model, os.path.join(run_dir, (B[0;1m[32m"model.joblib"[39m(B[m))[7;9Hmlflow.log_artifact(os.path.join(run_dir, (B[0;1m[32m"model.joblib"[39m(B[m))[8;9Hprint(f(B[0;1m[32m"Run poison={poison_fraction}: accuracy={acc:.4f}, precision={prec:.4f}, recall={rec:.4f}, f1={[39m(B[0;7m>[10;1H(B[0;1m[36mif[39m(B[m __name__ == (B[0;1m[32m"__main__"[39m(B[m:[11;5Hparser = argparse.ArgumentParser()[12;5Hparser.add_argument((B[0;1m[32m"--poison-levels"[39m(B[m, nargs=(B[0;1m[32m"+"[39m(B[m, type=float, default=[0.0, 0.05, 0.10, 0.50])[13;5Hparser.add_argument((B[0;1m[32m"--seed"[39m(B[m, type=int, default=42)[14;5Hparser.add_argument((B[0;1m[32m"--noise-std"[39m(B[m, type=float, default=0.5)[15;5Hparser.add_argument((B[0;1m[32m"--experiment-name"[39m(B[m, type=str, default=(B[0;1m[32m"iris_poisoning_experiment"[39m(B[m)[16;5Hargs = parser.parse_args()[17;5H(B[0;1m[36mfor[39m(B[m p (B[0;1m[36min[39m(B[m args.poison_levels:[18;9Hrun_experiment(p, seed=args.seed, noise_std=args.noise_std, experiment_name=args.experiment_name)[19d[?12l[?25h[?25l[38;16H            (B[0;7mM-D(B[m DOS Format             (B[0;7mM-A(B[m Append[17X[38;82H(B[0;7mM-B(B[m Backup File[K[39;2H(B[0;7mC(B[m Cancel[16G            (B[0;7mM-M(B[m Mac Format             (B[0;7mM-P(B[m Prepend[16X[39;82H(B[0;7m^T(B[m Browse[K[37d(B[0;7mFile Name to Write: iris_poisoning_mlflow.py                                                                   [37;45H(B[m[?12l[?25h[?25l   [1K (B[0;7m[ Writing... ](B[m[K[1;72H(B[0;7m [110G(B[m[37;47H(B[0;7m[ Wrote 87 lines ](B[m[38;16H(B[0;7m^O(B[m Write Out   (B[0;7m^W(B[m Where Is    (B[0;7m^K(B[m Cut         (B[0;7m^T(B[m Execute     (B[0;7m^C(B[m Location    (B[0;7mM-U(B[m Undo[39;2H(B[0;7mX(B[m Exit  [16G(B[0;7m^R(B[m Read File   (B[0;7m^\(B[m Replace     (B[0;7m^U(B[m Paste       (B[0;7m^J(B[m Justify     (B[0;7m^_(B[m Go To Line  (B[0;7mM-E(B[m Redo[19d[?12l[?25h[?25l[37d[J[39d[?12l[?25h[39;1H[?1049l[23;0;0t[?1l>[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mchmod +x iris_poiso[27m[7mn[27m[7ming_mlflow.py[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ chmod +x iris_poisoning_mlflow.py
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mls -l iris_poisonin[27m[7mg[27m[7m_mlflow.py[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ ls -l iris_poisoning_mlflow.py
[?2004l-rwxr-xr-x 1 satishsharma1911_gmail_com satishsharma1911_gmail_com 3963 Nov 16 12:19 [0m[01;32miris_poisoning_mlflow.py[0m
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython3 -m venv ven[27m[7mv[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python3 -m venv venv
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7msource venv/bin/act[27m[7mi[27m[7mvate[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ source venv/bin/activate
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpip install [27m[7m-[27m[7m-upgrade pip[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ pip install --upgrade pip
[?2004lRequirement already satisfied: pip in ./venv/lib/python3.10/site-packages (23.0.1)
Collecting pip
  Using cached pip-25.3-py3-none-any.whl (1.8 MB)
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.0.1
    Uninstalling pip-23.0.1:
      Successfully uninstalled pip-23.0.1
Successfully installed pip-25.3
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpip install [27m[7mm[27m[7mlflow scikit-learn matplotlib pandas numpy joblib[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ pip install mlflow scikit-learn matplotlib pandas numpy joblib
[?2004lCollecting mlflow
  Using cached mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)
Collecting scikit-learn
  Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting matplotlib
  Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)
Collecting pandas
  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)
Collecting numpy
  Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)
Collecting joblib
  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)
Collecting mlflow-skinny==3.6.0 (from mlflow)
  Using cached mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)
Collecting mlflow-tracing==3.6.0 (from mlflow)
  Using cached mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)
Collecting Flask-CORS<7 (from mlflow)
  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)
Collecting Flask<4 (from mlflow)
  Using cached flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)
Collecting alembic!=1.10.0,<2 (from mlflow)
  Downloading alembic-1.17.2-py3-none-any.whl.metadata (7.2 kB)
Collecting cryptography<47,>=43.0.0 (from mlflow)
  Using cached cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (5.7 kB)
Collecting docker<8,>=4.0.0 (from mlflow)
  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)
Collecting graphene<4 (from mlflow)
  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)
Collecting gunicorn<24 (from mlflow)
  Using cached gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)
Collecting huey<3,>=2.5.0 (from mlflow)
  Using cached huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)
Collecting pyarrow<23,>=4.0.0 (from mlflow)
  Using cached pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)
Collecting scipy<2 (from mlflow)
  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
Collecting sqlalchemy<3,>=1.4.0 (from mlflow)
  Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.5 kB)
Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.6.0->mlflow)
  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)
Collecting click<9,>=7.0 (from mlflow-skinny==3.6.0->mlflow)
  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
Collecting cloudpickle<4 (from mlflow-skinny==3.6.0->mlflow)
  Using cached cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)
Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)
Collecting fastapi<1 (from mlflow-skinny==3.6.0->mlflow)
  Downloading fastapi-0.121.2-py3-none-any.whl.metadata (28 kB)
Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.6.0->mlflow)
  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)
Collecting importlib_metadata!=4.7.0,<9,>=3.7.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)
Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)
Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)
Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)
Collecting packaging<26 (from mlflow-skinny==3.6.0->mlflow)
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.6.0->mlflow)
  Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)
Collecting pydantic<3,>=2.0.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)
Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)
Collecting pyyaml<7,>=5.1 (from mlflow-skinny==3.6.0->mlflow)
  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)
Collecting requests<3,>=2.17.3 (from mlflow-skinny==3.6.0->mlflow)
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)
Collecting typing-extensions<5,>=4.0.0 (from mlflow-skinny==3.6.0->mlflow)
  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting uvicorn<1 (from mlflow-skinny==3.6.0->mlflow)
  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn)
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting contourpy>=1.0.1 (from matplotlib)
  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)
Collecting cycler>=0.10 (from matplotlib)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools>=4.22.0 (from matplotlib)
  Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (112 kB)
Collecting kiwisolver>=1.3.1 (from matplotlib)
  Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
Collecting pillow>=8 (from matplotlib)
  Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)
Collecting pyparsing>=3 (from matplotlib)
  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)
Collecting python-dateutil>=2.7 (from matplotlib)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas)
  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas)
  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting Mako (from alembic!=1.10.0,<2->mlflow)
  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)
Collecting tomli (from alembic!=1.10.0,<2->mlflow)
  Using cached tomli-2.3.0-py3-none-any.whl.metadata (10 kB)
Collecting cffi>=2.0.0 (from cryptography<47,>=43.0.0->mlflow)
  Using cached cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)
  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)
Collecting urllib3>=1.26.0 (from docker<8,>=4.0.0->mlflow)
  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)
Collecting starlette<0.50.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)
  Using cached starlette-0.49.3-py3-none-any.whl.metadata (6.4 kB)
Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)
  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)
Collecting blinker>=1.9.0 (from Flask<4->mlflow)
  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)
Collecting itsdangerous>=2.2.0 (from Flask<4->mlflow)
  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)
Collecting jinja2>=3.1.2 (from Flask<4->mlflow)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting markupsafe>=2.1.1 (from Flask<4->mlflow)
  Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
Collecting werkzeug>=3.1.0 (from Flask<4->mlflow)
  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)
Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow)
  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)
Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow)
  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)
Collecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)
  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)
Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)
  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)
Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)
  Using cached graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)
Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)
  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)
Collecting zipp>=3.20 (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow)
  Using cached zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)
Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow)
  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)
Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow)
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.41.5 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow)
  Using cached pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
Collecting typing-inspection>=0.4.2 (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow)
  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)
Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Collecting charset_normalizer<4,>=2 (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow)
  Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
Collecting idna<4,>=2.5 (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow)
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting certifi>=2017.4.17 (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow)
  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)
  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)
Collecting greenlet>=1 (from sqlalchemy<3,>=1.4.0->mlflow)
  Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)
Collecting anyio<5,>=3.6.2 (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow)
  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)
Collecting exceptiongroup>=1.0.2 (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow)
  Using cached exceptiongroup-1.3.0-py3-none-any.whl.metadata (6.7 kB)
Collecting sniffio>=1.1 (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow)
  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.6.0->mlflow)
  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
Collecting pycparser (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow)
  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Using cached mlflow-3.6.0-py3-none-any.whl (8.9 MB)
Using cached mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)
Using cached mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)
Using cached scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)
Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)
Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)
Using cached numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
Downloading alembic-1.17.2-py3-none-any.whl (248 kB)
Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)
Downloading click-8.3.1-py3-none-any.whl (108 kB)
Using cached cloudpickle-3.1.2-py3-none-any.whl (22 kB)
Using cached cryptography-46.0.3-cp38-abi3-manylinux_2_28_x86_64.whl (4.5 MB)
Using cached databricks_sdk-0.73.0-py3-none-any.whl (753 kB)
Using cached docker-7.1.0-py3-none-any.whl (147 kB)
Downloading fastapi-0.121.2-py3-none-any.whl (109 kB)
Using cached flask-3.1.2-py3-none-any.whl (103 kB)
Using cached flask_cors-6.0.1-py3-none-any.whl (13 kB)
Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)
Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)
Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)
Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)
Using cached graphql_core-3.2.7-py3-none-any.whl (207 kB)
Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)
Using cached gunicorn-23.0.0-py3-none-any.whl (85 kB)
Using cached huey-2.5.4-py3-none-any.whl (76 kB)
Using cached importlib_metadata-8.7.0-py3-none-any.whl (27 kB)
Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)
Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)
Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)
Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Downloading protobuf-6.33.1-cp39-abi3-manylinux2014_x86_64.whl (323 kB)
Using cached pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)
Using cached pydantic-2.12.4-py3-none-any.whl (463 kB)
Using cached pydantic_core-2.41.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)
Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached rsa-4.9.1-py3-none-any.whl (34 kB)
Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
Using cached smmap-5.0.2-py3-none-any.whl (24 kB)
Using cached sqlalchemy-2.0.44-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)
Using cached sqlparse-0.5.3-py3-none-any.whl (44 kB)
Using cached starlette-0.49.3-py3-none-any.whl (74 kB)
Using cached anyio-4.11.0-py3-none-any.whl (109 kB)
Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)
Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)
Using cached joblib-1.5.2-py3-none-any.whl (308 kB)
Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)
Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)
Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached exceptiongroup-1.3.0-py3-none-any.whl (16 kB)
Using cached fonttools-4.60.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)
Using cached greenlet-3.2.4-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (584 kB)
Using cached h11-0.16.0-py3-none-any.whl (37 kB)
Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
Using cached markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)
Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)
Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)
Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)
Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)
Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)
Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)
Using cached zipp-3.23.0-py3-none-any.whl (10 kB)
Using cached mako-1.3.10-py3-none-any.whl (78 kB)
Using cached pycparser-2.23-py3-none-any.whl (118 kB)
Using cached tomli-2.3.0-py3-none-any.whl (14 kB)
Installing collected packages: pytz, huey, zipp, urllib3, tzdata, typing-extensions, tomli, threadpoolctl, sqlparse, sniffio, smmap, six, pyyaml, python-dotenv, pyparsing, pycparser, pyasn1, pyarrow, protobuf, pillow, packaging, numpy, markupsafe, kiwisolver, joblib, itsdangerous, idna, h11, greenlet, graphql-core, fonttools, cycler, cloudpickle, click, charset_normalizer, certifi, cachetools, blinker, annotated-types, annotated-doc, werkzeug, uvicorn, typing-inspection, sqlalchemy, scipy, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, opentelemetry-proto, Mako, jinja2, importlib_metadata, gunicorn, graphql-relay, gitdb, exceptiongroup, contourpy, cffi, scikit-learn, pydantic, pandas, opentelemetry-api, matplotlib, graphene, google-auth, gitpython, Flask, docker, cryptography, anyio, alembic, starlette, opentelemetry-semantic-conventions, Flask-CORS, databricks-sdk, opentelemetry-sdk, fastapi, mlflow-tracing, mlflow-skinny, mlflow
[?25l[2K   [38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m 1/82[0m [huey][2K   [38;5;197mâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m 3/82[0m [urllib3][2K   [38;5;197mâ”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m 6/82[0m [tomli][2K   [38;5;197mâ”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12/82[0m [pyyaml][2K   [38;5;197mâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m15/82[0m [pycparser][2K   [38;5;197mâ”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m16/82[0m [pyasn1][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m17/82[0m [pyarrow][2K   [38;5;197mâ”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m18/82[0m [protobuf][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m19/82[0m [pillow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m19/82[0m [pillow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m21/82[0m [numpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m23/82[0m [kiwisolver][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m24/82[0m [joblib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m26/82[0m [idna][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m28/82[0m [greenlet][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m29/82[0m [graphql-core][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m30/82[0m [fonttools][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m34/82[0m [charset_normalizer][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m40/82[0m [werkzeug][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m41/82[0m [uvicorn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m43/82[0m [sqlalchemy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m44/82[0m [scipy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m47/82[0m [python-dateutil][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m49/82[0m [pyasn1-modules][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m51/82[0m [Mako][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m54/82[0m [gunicorn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m [32m58/82[0m [contourpy][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m60/82[0m [scikit-learn][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m61/82[0m [pydantic][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m61/82[0m [pydantic][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m [32m61/82[0m [pydantic][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m62/82[0m [pandas][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m [32m63/82[0m [opentelemetry-api][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m64/82[0m [matplotlib][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m [32m65/82[0m [graphene][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m [32m66/82[0m [google-auth][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m [32m68/82[0m [Flask][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m [32m70/82[0m [cryptography][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m [32m70/82[0m [cryptography][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m [32m72/82[0m [alembic][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m [32m72/82[0m [alembic][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m [32m74/82[0m [opentelemetry-semantic-conventions][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m [32m76/82[0m [databricks-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m [32m76/82[0m [databricks-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m [32m76/82[0m [databricks-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m [32m76/82[0m [databricks-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m [32m76/82[0m [databricks-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”â”[0m [32m77/82[0m [opentelemetry-sdk][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m[38;5;237mâ”[0m [32m79/82[0m [mlflow-tracing][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m [32m80/82[0m [mlflow-skinny][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;197mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;197mâ•¸[0m [32m81/82[0m [mlflow][2K   [38;5;70mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m82/82[0m [mlflow]
[?25h[1A[2KSuccessfully installed Flask-3.1.2 Flask-CORS-6.0.1 Mako-1.3.10 alembic-1.17.2 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.11.0 blinker-1.9.0 cachetools-6.2.2 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpickle-3.1.2 contourpy-1.3.2 cryptography-46.0.3 cycler-0.12.1 databricks-sdk-0.73.0 docker-7.1.0 exceptiongroup-1.3.0 fastapi-0.121.2 fonttools-4.60.1 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.43.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 greenlet-3.2.4 gunicorn-23.0.0 h11-0.16.0 huey-2.5.4 idna-3.11 importlib_metadata-8.7.0 itsdangerous-2.2.0 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 markupsafe-3.0.3 matplotlib-3.10.7 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 numpy-2.2.6 opentelemetry-api-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 packaging-25.0 pandas-2.3.3 pillow-12.0.0 protobuf-6.33.1 pyarrow-22.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pycparser-2.23 pydantic-2.12.4 pydantic-core-2.41.5 pyparsing-3.2.5 python-dateutil-2.9.0.post0 python-dotenv-1.2.1 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 rsa-4.9.1 scikit-learn-1.7.2 scipy-1.15.3 six-1.17.0 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.44 sqlparse-0.5.3 starlette-0.49.3 threadpoolctl-3.6.0 tomli-2.3.0 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 urllib3-2.5.0 uvicorn-0.38.0 werkzeug-3.1.3 zipp-3.23.0
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mscreen -S ml[27m[7mf[27m[7mlow[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ screen -S mlflow
[?2004l[!p[?3;4l[4l>[?1049h[22;0;0t[4l[?1h=[0m(B[1;39r[H[2J[H[2J(base) [1m[32msatishsharma1911_gmail_com@instance-20251031-150440[0m:[1m[34m~/iris_dvc_pipeline_mlops/week8[0m$ mlflow server --backend-store-uri sqlite:///mlflow.db \
>   --default-artifact-root ./mlruns \
>   --host 0.0.0.0 --port 5000
2025/11/16 12:29:22 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:29:22 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values
2025-11-16 12:29:22 INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table
2025-11-16 12:29:23 INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db
2025-11-16 12:29:23 INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.
2025-11-16 12:29:23 INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table
2025-11-16 12:29:23 INFO  [alembic.runtime.migration] Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
2025/11/16 12:29:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:29:24 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:29:24 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[MLflow] Security middleware enabled with default settings (localhost-only). To allow connections from other hosts, use --host 0.0.0.0 and configure --allowed-hosts and --cors-allowed-origins.
[32mINFO[39m:     Uvicorn running on [1mhttp://0.0.0.0:5000[0m (Press CTRL+C to quit)
[32mINFO[39m:     Started parent process [[36m[1m11734[0m]
[32mINFO[39m:     Started server process [[36m11738[39m]
[32mINFO[39m:     Waiting for application startup.
[32mINFO[39m:     Application startup complete.
[32mINFO[39m:     Started server process [[36m11736[39m]
[32mINFO[39m:     Waiting for application startup.
[32mINFO[39m:     Application startup complete.
[32mINFO[39m:     Started server process [[36m11737[39m]
[32mINFO[39m:     Waiting for application startup.
[32mINFO[39m:     Application startup complete.
[32mINFO[39m:     Started server process [[36m11739[39m]
[32mINFO[39m:     Waiting for application startup.
[32mINFO[39m:     Application startup complete.
[32mINFO[39m:     127.0.0.1:37050 - "[1mGET / HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:37050 - "[1mGET /static-files/static/js/main.380f9aea.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:37064 - "[1mGET /static-files/static/css/main.280d6c90.css HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44660 - "[1mGET /static-files/static/js/3617.10568100.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44688 - "[1mGET /static-files/static/js/762.335831d3.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44674 - "[1mGET /static-files/static/js/5759.45405231.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44666 - "[1mGET /static-files/static/css/762.26533251.chunk.css HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44660 - "[1mGET /static-files/favicon.ico HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44674 - "[1mGET /static-files/manifest.json HTTP/1.1[0m" [32m200 OK[39m
2025/11/16 12:31:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:31:40 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:31:40 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:31:40 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
2025-11-16 12:31:40 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:31:40 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[32mINFO[39m:     127.0.0.1:44688 - "[1mGET /ajax-api/2.0/mlflow/experiments/search?max_results=5&order_by=last_update_time+DESC HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44184 - "[1mGET /static-files/static/css/4783.26533251.chunk.css HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44190 - "[1mGET /static-files/static/js/4783.f5694ee4.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44190 - "[1mGET /ajax-api/2.0/mlflow/experiments/search?max_results=25&order_by=last_update_time+DESC HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44196 - "[1mGET /static-files/static/css/7679.73d820e1.chunk.css HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44200 - "[1mGET /static-files/static/js/2820.e9a9d989.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44210 - "[1mGET /static-files/static/js/7679.5be5e428.chunk.js HTTP/1.1[0m" [32m200 OK[39m
2025/11/16 12:31:57 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:31:57 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:31:57 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:31:57 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[32mINFO[39m:     127.0.0.1:44200 - "[1mGET /ajax-api/2.0/mlflow/registered-models/search?filter=&max_results=25&order_by=name+ASC HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44200 - "[1mGET /static-files/static/js/4977.bb23021b.chunk.js HTTP/1.1[0m" [32m200 OK[39m
[32mINFO[39m:     127.0.0.1:44210 - "[1mGET /static-files/static/js/3912.487900b2.chunk.js HTTP/1.1[0m" [32m200 OK[39m
2025/11/16 12:32:01 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:32:01 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:32:01 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:32:01 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[32mINFO[39m:     127.0.0.1:44210 - "[1mGET /ajax-api/2.0/mlflow/registered-models/search?filter=tags.%60mlflow.prompt.is_prompt%60+%3D+%27true%27 HTTP/1.1[0m" [32m200 OK[39m
2025/11/16 12:32:03 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/11/16 12:32:03 INFO mlflow.store.db.utils: Updating database tables
2025-11-16 12:32:03 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:32:03 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
2025-11-16 12:32:03 INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
2025-11-16 12:32:03 INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[32mINFO[39m:     127.0.0.1:44210 - "[1mGET /ajax-api/2.0/mlflow/experiments/search?max_results=25&order_by=last_update_time+DESC HTTP/1.1[0m" [32m200 OK[39m
[?1l>[39;1H
[?1049l[23;0;0t[detached from 11715.mlflow]
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython iris_[27m[7mp[27m[7moisoning_mlflow.py --poison-levels 0.0 0.05 0.10 0.50[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow.py --poison-levels 0.0 0.05 0.10 0.50
[?2004l/home/satishsharma1911_gmail_com/iris_dvc_pipeline_mlops/week8/venv/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/utils.py:140: FutureWarning: Filesystem tracking backend (e.g., './mlruns') is deprecated. Please switch to a database backend (e.g., 'sqlite:///mlflow.db'). For feedback, see: https://github.com/mlflow/mlflow/issues/18534
  return FileStore(store_uri, store_uri)
2025/11/16 12:32:29 INFO mlflow.tracking.fluent: Experiment with name 'iris_poisoning_experiment' does not exist. Creating a new experiment.
2025/11/16 12:32:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:32:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Run poison=0.0: accuracy=0.9000, precision=0.9024, recall=0.9000, f1=0.8997
2025/11/16 12:32:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:32:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Run poison=0.05: accuracy=0.9333, precision=0.9333, recall=0.9333, f1=0.9333
2025/11/16 12:32:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:32:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Run poison=0.1: accuracy=0.9333, precision=0.9333, recall=0.9333, f1=0.9333
2025/11/16 12:32:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:32:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
Run poison=0.5: accuracy=0.9333, precision=0.9333, recall=0.9333, f1=0.9333
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mscreen -ls[27mscreen -ls
[?2004lThere is a screen on:
	11715.mlflow	(11/16/25 12:29:07)	(Detached)
1 Socket in /run/screen/S-satishsharma1911_gmail_com.
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mexport MLFLO[27m[7mW[27m[7m_TRACKING_URI=http://127.0.0.1:5000[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ export MLFLOW_TRACKING_URI=http://127.0.0.1:5000
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mecho $MLFLOW[27m[7m_[27m[7mTRACKING_URI[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ echo $MLFLOW_TRACKING_URI
[?2004lhttp://127.0.0.1:5000
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython iris_[27m[7mp[27m[7moisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0
[?2004lpython: can't open file '/home/satishsharma1911_gmail_com/iris_dvc_pipeline_mlops/week8/iris_poisoning_mlflow_debug.py': [Errno 2] No such file or directory
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ ls -ahl
[?2004ltotal 568K
drwxr-xr-x  6 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:29 [0m[01;34m.[0m
drwxr-xr-x 13 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:10 [01;34m..[0m
drwxr-xr-x  8 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:17 [01;34m.git[0m
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com  559 Nov 16 12:18 README-week5.md
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 3.2K Nov 16 12:13 README.md
-rwxr-xr-x  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 3.9K Nov 16 12:19 [01;32miris_poisoning_mlflow.py[0m
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 440K Nov 16 12:29 mlflow.db
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com 1021 Nov 16 12:18 mlflow_test.py
drwxr-xr-x  4 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:32 [01;34mmlruns[0m
drwxr-xr-x  5 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:18 [01;34mmlruns_copy[0m
-rw-r--r--  1 satishsharma1911_gmail_com satishsharma1911_gmail_com  84K Nov 16 12:32 myscript.txt
drwxr-xr-x  6 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 12:21 [01;34mvenv[0m
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cat > iris_poisoning_mlflow_debug.py <<'PY' 
#!/usr/bin/env python3
"""
iris_poisoning_mlflow_debug.py

Enhanced debug version:
- Uses MLFLOW_TRACKING_URI env var if present (defaults to http://127.0.0.1:5000)
- Logs n_poisoned_samples, pre/post training stats, poisoned indices (sample),
  and metrics: accuracy, precision_macro, recall_macro, f1_macro.
- Saves confusion matrix PNG and a small JSON summary per run.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    # If user set MLFLOW_TRACKING_URI outside, respect it. Otherwise default to localhost server.
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):    rng = np.random.RandomState(seed)    Xp = X.copy()    n = Xp.shape[0]    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, cm[i, j], ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    # Set experiment    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        client = MlflowClient()        # Log parameters        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split (test set kept clean)        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # Pre-poison stats        stats_before = {            "mean": X_train.mean(axis=0).tolist(),            "std": X_train.std(axis=0).tolist(),            "shape": X_train.shape        }        # Poison training data only        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # Post-poison stats        stats_after = {            "mean": Xp_train.mean(axis=0).tolist(),            "std": Xp_train.std(axis=0).tolist(),            "shape": Xp_train.shape        }        # Log debug metrics (first feature example + number of poisoned)        mlflow.log_metric("n_poisoned_samples", len(poisoned_idx))        # log means/std of feature 0 as quick scalar comparisons (others saved in json artifact)        mlflow.log_metric("train_mean_feature0_before", stats_before["mean"][0])        mlflow.log_metric("train_mean_feature0_after", stats_after["mean"][0])        mlflow.log_metric("train_std_feature0_before", stats_before["std"][0])        mlflow.log_metric("train_std_feature0_after", stats_after["std"][0])        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Predict on clean test set        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        # Log metrics        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Save model to run artifacts and log it        artifact_dir = "artifacts"        # mlflow.sklearn.log_model handles artifact storage via server        mlflow.sklearn.log_model(model, "model")        # Prepare artifact folder inside local workspace (for extra artifacts)        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Confusion matrix image        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Save debug json containing stats & a short sample of poisoned indices        debug_info = {[7m            "run_id": run_id,[27m[7m            "poison_fraction": poison_fraction,[27m[7m            "n_poisoned_samples": len(poisoned_idx),[27m[7m            "poisoned_indices_sample": poisoned_idx[:20],[27m[7m            "stats_before": stats_before,[27m[7m            "stats_after": stats_after,[27m[7m            "metrics": {"accuracy": acc, "precision_macro": prec, "recall_macro": rec, "f1_macro": f1}[27m[7m        }[27m[7m        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")[27m[7m        with open(debug_path, "w") as f:[27m[7m            json.dump(debug_info, f, indent=2)[27m[7m        mlflow.log_artifact(debug_path)[27m[7m        # Also store the trained model file as a joblib artifact (optional)[27m[7m        model_joblib = os.path.join(local_run_dir, "model.joblib")[27m[7m        joblib.dump(model, model_joblib)[27m[7m        mlflow.log_artifact(model_joblib)[27m[7m        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={len(poisoned_idx)} acc={acc:.4f}")[27m[7mdef main():[27m[7m    ensure_tracking_uri()[27m[7m    parser = argparse.ArgumentParser()[27m[7m    parser.add_argument("--poison-levels", nargs="+", type=float, default=[0.0, 0.05, 0.10, 0.50],[27m[7m                        help="List of poison fractions (e.g. 0.05 for 5%)")[27m[7m    parser.add_argument("--seed", type=int, default=42)[27m[7m    parser.add_argument("--noise-std", type=float, default=1.0)[27m[7m    parser.add_argument("--n-estimators", type=int, default=200)[27m[7m    parser.add_argument("--experiment-name", type=str, default="iris_poisoning_experiment_debug")[27m[7m    args = parser.parse_args()[27m[7m    # set the experiment name once (user visible)[27m[7m    for p in args.poison_levels:[27m[7m        run_experiment(poison_fraction=p, seed=args.seed, noise_std=args.noise_std,[27m[7m                       n_estimators=args.n_estimators, experiment_name=args.experiment_name)[27m[7mif __name__ == "__main__":[27m[7m    main()[27m[7mPY[27m            "run_id": run_id,            "poison_fraction": poison_fraction,            "n_poisoned_samples": len(poisoned_idx),            "poisoned_indices_sample": poisoned_idx[:20],            "stats_before": stats_before,            "stats_after": stats_after,            "metrics": {"accuracy": acc, "precision_macro": prec, "recall_macro": rec, "f1_macro": f1}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also store the trained model file as a joblib artifact (optional)        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={len(poisoned_idx)} acc={acc:.4f}")def main():    ensure_tracking_uri()    parser = argparse.ArgumentParser()    parser.add_argument("--poison-levels", nargs="+", type=float, default=[0.0, 0.05, 0.10, 0.50],                        help="List of poison fractions (e.g. 0.05 for 5%)")    parser.add_argument("--seed", type=int, default=42)    parser.add_argument("--noise-std", type=float, default=1.0)    parser.add_argument("--n-estimators", type=int, default=200)    parser.add_argument("--experiment-name", type=str, default="iris_poisoning_experiment_debug")    args = parser.parse_args()    # set the experiment name once (user visible)    for p in args.poison_levels:        run_experiment(poison_fraction=p, seed=args.seed, noise_std=args.noise_std,                       n_estimators=args.n_estimators, experiment_name=args.experiment_name)if __name__ == "__main__":    main()PY
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cat iris [K_poisoning_mlflow_debug.py 
[?2004l#!/usr/bin/env python3
"""
iris_poisoning_mlflow_debug.py

Enhanced debug version:
- Uses MLFLOW_TRACKING_URI env var if present (defaults to http://127.0.0.1:5000)
- Logs n_poisoned_samples, pre/post training stats, poisoned indices (sample),
  and metrics: accuracy, precision_macro, recall_macro, f1_macro.
- Saves confusion matrix PNG and a small JSON summary per run.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    # If user set MLFLOW_TRACKING_URI outside, respect it. Otherwise default to localhost server.
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))
    poisoned_idx = []
    if k > 0:
        poisoned_idx = rng.choice(n, k, replace=False)
        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)
        Xp[poisoned_idx] += noise
    return Xp, y, poisoned_idx

def plot_and_save_cm(y_true, y_pred, outdir, label):
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,3))
    im = ax.imshow(cm, interpolation='nearest')
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, cm[i, j], ha="center", va="center")
    ax.set_title(f"Confusion Matrix: {label}")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    plt.tight_layout()
    outpath = os.path.join(outdir, f"confusion_{label}.png")
    fig.savefig(outpath)
    plt.close(fig)
    return outpath

def run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):
    # Set experiment
    mlflow.set_experiment(experiment_name)
    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"
    with mlflow.start_run(run_name=run_name) as run:
        run_id = run.info.run_id
        client = MlflowClient()
        # Log parameters
        mlflow.log_param("poison_fraction", poison_fraction)
        mlflow.log_param("noise_std", noise_std)
        mlflow.log_param("seed", seed)
        mlflow.log_param("n_estimators", n_estimators)

        # Load data and split (test set kept clean)
        iris = load_iris()
        X, y = iris.data, iris.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=seed, stratify=y
        )

        # Pre-poison stats
        stats_before = {
            "mean": X_train.mean(axis=0).tolist(),
            "std": X_train.std(axis=0).tolist(),
            "shape": X_train.shape
        }
        # Poison training data only
        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)

        # Post-poison stats
        stats_after = {
            "mean": Xp_train.mean(axis=0).tolist(),
            "std": Xp_train.std(axis=0).tolist(),
            "shape": Xp_train.shape
        }

        # Log debug metrics (first feature example + number of poisoned)
        mlflow.log_metric("n_poisoned_samples", len(poisoned_idx))
        # log means/std of feature 0 as quick scalar comparisons (others saved in json artifact)
        mlflow.log_metric("train_mean_feature0_before", stats_before["mean"][0])
        mlflow.log_metric("train_mean_feature0_after", stats_after["mean"][0])
        mlflow.log_metric("train_std_feature0_before", stats_before["std"][0])
        mlflow.log_metric("train_std_feature0_after", stats_after["std"][0])

        # Train model
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)
        model.fit(Xp_train, yp_train)

        # Predict on clean test set
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

        # Log metrics
        mlflow.log_metric("accuracy", float(acc))
        mlflow.log_metric("precision_macro", float(prec))
        mlflow.log_metric("recall_macro", float(rec))
        mlflow.log_metric("f1_macro", float(f1))

        # Save model to run artifacts and log it
        artifact_dir = "artifacts"
        # mlflow.sklearn.log_model handles artifact storage via server
        mlflow.sklearn.log_model(model, "model")

        # Prepare artifact folder inside local workspace (for extra artifacts)
        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")
        os.makedirs(local_run_dir, exist_ok=True)

        # Confusion matrix image
        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")
        mlflow.log_artifact(cm_path)

        # Save debug json containing stats & a short sample of poisoned indices
        debug_info = {
            "run_id": run_id,
            "poison_fraction": poison_fraction,
            "n_poisoned_samples": len(poisoned_idx),
            "poisoned_indices_sample": poisoned_idx[:20],
            "stats_before": stats_before,
            "stats_after": stats_after,
            "metrics": {"accuracy": acc, "precision_macro": prec, "recall_macro": rec, "f1_macro": f1}
        }
        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")
        with open(debug_path, "w") as f:
            json.dump(debug_info, f, indent=2)
        mlflow.log_artifact(debug_path)

        # Also store the trained model file as a joblib artifact (optional)
        model_joblib = os.path.join(local_run_dir, "model.joblib")
        joblib.dump(model, model_joblib)
        mlflow.log_artifact(model_joblib)

        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={len(poisoned_idx)} acc={acc:.4f}")

def main():
    ensure_tracking_uri()
    parser = argparse.ArgumentParser()
    parser.add_argument("--poison-levels", nargs="+", type=float, default=[0.0, 0.05, 0.10, 0.50],
                        help="List of poison fractions (e.g. 0.05 for 5%)")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--noise-std", type=float, default=1.0)
    parser.add_argument("--n-estimators", type=int, default=200)
    parser.add_argument("--experiment-name", type=str, default="iris_poisoning_experiment_debug")
    args = parser.parse_args()

    # set the experiment name once (user visible)
    for p in args.poison_levels:
        run_experiment(poison_fraction=p, seed=args.seed, noise_std=args.noise_std,
                       n_estimators=args.n_estimators, experiment_name=args.experiment_name)

if __name__ == "__main__":
    main()
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mchmod +x iri[27m[7ms[27m[7m_poisoning_mlflow_debug.py[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ chmod +x iris_poisoning_mlflow_debug.py
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mcurl -s http[27m[7m:[27m[7m//127.0.0.1:5000/ | head -n 5[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ curl -s http://127.0.0.1:5000/ | head -n 5
[?2004l<!doctype html><html lang="en"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no"/><link rel="shortcut icon" href="./static-files/favicon.ico"/><meta name="theme-color" content="#000000"/><link rel="manifest" href="./static-files/manifest.json" crossorigin="use-credentials"/><title>MLflow</title><script defer="defer" src="static-files/static/js/main.380f9aea.js"></script><link href="static-files/static/css/main.280d6c90.css" rel="stylesheet"></head><body><noscript>You need to enable JavaScript to run this app.</noscript><div id="root" class="mlflow-ui-container"></div><div id="modal" class="mlflow-ui-container"></div></body></html>[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython iris_[27m[7mp[27m[7moisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50
[?2004l2025/11/16 12:49:07 INFO mlflow.tracking.fluent: Experiment with name 'iris_poisoning_experiment_debug' does not exist. Creating a new experiment.
2025/11/16 12:49:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:49:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[run f23127c5b39140d8b23bb8156f8be241] poison=0.0 n_poisoned=0 acc=0.9000
ğŸƒ View run poison_0pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/f23127c5b39140d8b23bb8156f8be241
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
2025/11/16 12:49:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 12:49:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
ğŸƒ View run poison_5pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/e7a8f72f821d4137955b06c826610b80
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
Traceback (most recent call last):
  File "/home/satishsharma1911_gmail_com/iris_dvc_pipeline_mlops/week8/iris_poisoning_mlflow_debug.py", line 181, in <module>
    main()
  File "/home/satishsharma1911_gmail_com/iris_dvc_pipeline_mlops/week8/iris_poisoning_mlflow_debug.py", line 177, in main
    run_experiment(poison_fraction=p, seed=args.seed, noise_std=args.noise_std,
  File "/home/satishsharma1911_gmail_com/iris_dvc_pipeline_mlops/week8/iris_poisoning_mlflow_debug.py", line 154, in run_experiment
    json.dump(debug_info, f, indent=2)
  File "/opt/conda/lib/python3.10/json/__init__.py", line 179, in dump
    for chunk in iterable:
  File "/opt/conda/lib/python3.10/json/encoder.py", line 431, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/opt/conda/lib/python3.10/json/encoder.py", line 405, in _iterencode_dict
    yield from chunks
  File "/opt/conda/lib/python3.10/json/encoder.py", line 438, in _iterencode
    o = _default(o)
  File "/opt/conda/lib/python3.10/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ndarray is not JSON serializable
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cat > iris_poisoning_mlflow_debug.py <<'PY' 
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))[7m        mlflow.log_metric("f1_macro", float(f1))[27m[7m        # Log model using mlflow (server will store it)[27m[7m        mlflow.sklearn.log_model(model, "model")[27m[7m        # Ensure local artifact dir exists[27m[7m        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")[27m[7m        os.makedirs(local_run_dir, exist_ok=True)[27m[7m        # Save confusion matrix PNG[27m[7m        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")[27m[7m        mlflow.log_artifact(cm_path)[27m[7m        # Build JSON-serializable debug info[27m[7m        debug_info = {[27m[7m            "run_id": run_id,[27m[7m            "poison_fraction": to_py(poison_fraction),[27m[7m            "n_poisoned_samples": int(np.size(poisoned_idx)),[27m[7m            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],[27m[7m            "stats_before": to_py(stats_before),[27m[7m            "stats_after": to_py(stats_after),[27m[7m            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1[27m[7m_macro": to_py(f1)}[27m[7m        }[27m[7m        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")[27m[7m        with open(debug_path, "w") as f:[27m[7m            json.dump(debug_info, f, indent=2)[27m[7m        mlflow.log_artifact(debug_path)[27m[7m        # Also save model.joblib locally and log it as artifact[27m[7m        model_joblib = os.path.join(local_run_dir, "model.joblib")[27m[7m        joblib.dump(model, model_joblib)[27m[7m        mlflow.log_artifact(model_joblib)[27m[7m        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")[27m[7mPY[27m        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PY
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mchmod +x iri[27m[7ms[27m[7m_poisoning_mlflow_debug.py[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ chmod +x iris_poisoning_mlflow_debug.py
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython iris_[27m[7mp[27m[7moisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0[27m[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ chmod +x iris[49P_poisoning_mlflow_debug.py[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat > iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PY[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ curl -s http:[30P//127.0.0.1:5000/ | head -n 5[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Chmod +x iris[3P_poisoning_mlflow_debug.py[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Curl -s http://127.0.0.1:5000/ | head -n 5[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ curl -s http:[30P//127.0.0.1:5000/ | head -n 5[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Chmod +x iris[3P_poisoning_mlflow_debug.py[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat iris_pois[4Poning_mlflow_debug.py [A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [C[C[C[C> iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
iris_poisoning_mlflow_debug.py

Enhanced debug version:
- Uses MLFLOW_TRACKING_URI env var if present (defaults to http://127.0.0.1:5000)
- Logs n_poisoned_samples, pre/post training stats, poisoned indices (sample),
  and metrics: accuracy, precision_macro, recall_macro, f1_macro.
- Saves confusion matrix PNG and a small JSON summary per run.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    # If user set MLFLOW_TRACKING_URI outside, respect it. Otherwise default to localhost server.
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):    rng = np.random.RandomState(seed)    Xp = X.copy()    n = Xp.shape[0]    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, cm[i, j], ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    # Set experiment    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        client = MlflowClient()        # Log parameters        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split (test set kept clean)        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # Pre-poison stats        stats_before = {            "mean": X_train.mean(axis=0).tolist(),            "std": X_train.std(axis=0).tolist(),            "shape": X_train.shape        }        # Poison training data only        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # Post-poison stats        stats_after = {            "mean": Xp_train.mean(axis=0).tolist(),            "std": Xp_train.std(axis=0).tolist(),            "shape": Xp_train.shape        }        # Log debug metrics (first feature example + number of poisoned)        mlflow.log_metric("n_poisoned_samples", len(poisoned_idx))        # log means/std of feature 0 as quick scalar comparisons (others saved in json artifact)        mlflow.log_metric("train_mean_feature0_before", stats_before["mean"][0])        mlflow.log_metric("train_mean_feature0_after", stats_after["mean"][0])        mlflow.log_metric("train_std_feature0_before", stats_before["std"][0])        mlflow.log_metric("train_std_feature0_after", stats_after["std"][0])        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Predict on clean test set        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        # Log metrics        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Save model to run artifacts and log it        artifact_dir = "artifacts"        # mlflow.sklearn.log_model handles artifact storage via server        mlflow.sklearn.log_model(model, "model")        # Prepare artifact folder inside local workspace (for extra artifacts)        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Confusion matrix image        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Save debug json containing stats & a short sample of poisoned indices        debug_info = {            "run_id": run_id,            "poison_fraction": poison_fraction,            "n_poisoned_samples": len(poisoned_idx),            "poisoned_indices_sample": poisoned_idx[:20],            "stats_before": stats_before,            "stats_after": stats_after,            "metrics": {"accuracy": acc, "precision_macro": prec, "recall_macro": rec, "f1_macro": f1}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also store the trained model file as a joblib artifact (optional)        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={len(poisoned_idx)} acc={acc:.4f}")def main():    ensure_tracking_uri()    parser = argparse.ArgumentParser()    parser.add_argument("--poison-levels", nargs="+", type=float, default=[0.0, 0.05, 0.10, 0.50],                        help="List of poison fractions (e.g. 0.05 for 5%)")    parser.add_argument("--seed", type=int, default=42)    parser.add_argument("--noise-std", type=float, default=1.0)    parser.add_argument("--n-estimators", type=int, default=200)    parser.add_argument("--experiment-name", type=str, default="iris_poisoning_experiment_debug")    args = parser.parse_args()    # set the experiment name once (user visible)    for p in args.poison_levels:        run_experiment(poison_fraction=p, seed=args.seed, noise_std=args.noise_std,                       n_estimators=args.n_estimators, experiment_name=args.experiment_name)if __name__ == "__main__":    main()PY[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ciris_pois[8Poning_mlflow_debug.py 
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C
[?2004l#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))
    poisoned_idx = []
    if k > 0:
        poisoned_idx = rng.choice(n, k, replace=False)
        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)
        Xp[poisoned_idx] += noise
    # return poisoned_idx as numpy array or list â€” we'll normalize later
    return Xp, y, poisoned_idx

def plot_and_save_cm(y_true, y_pred, outdir, label):
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,3))
    im = ax.imshow(cm, interpolation='nearest')
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, int(cm[i, j]), ha="center", va="center")
    ax.set_title(f"Confusion Matrix: {label}")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    plt.tight_layout()
    outpath = os.path.join(outdir, f"confusion_{label}.png")
    fig.savefig(outpath)
    plt.close(fig)
    return outpath

def to_py(x):
    """Convert numpy types/arrays to native Python types for JSON serialization."""
    if isinstance(x, np.ndarray):
        return x.tolist()
    if isinstance(x, (np.floating, np.integer)):
        return x.item()
    if isinstance(x, (list, tuple)):
        return [to_py(i) for i in x]
    if isinstance(x, dict):
        return {k: to_py(v) for k, v in x.items()}
    return x

def run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):
    mlflow.set_experiment(experiment_name)
    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"
    with mlflow.start_run(run_name=run_name) as run:
        run_id = run.info.run_id
        # Log params
        mlflow.log_param("poison_fraction", poison_fraction)
        mlflow.log_param("noise_std", noise_std)
        mlflow.log_param("seed", seed)
        mlflow.log_param("n_estimators", n_estimators)

        # Load data and split
        iris = load_iris()
        X, y = iris.data, iris.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=seed, stratify=y
        )

        # stats before
        stats_before = {
            "mean": to_py(X_train.mean(axis=0)),
            "std": to_py(X_train.std(axis=0)),
            "shape": X_train.shape
        }

        # poison training set
        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)

        # stats after
        stats_after = {
            "mean": to_py(Xp_train.mean(axis=0)),
            "std": to_py(Xp_train.std(axis=0)),
            "shape": Xp_train.shape
        }

        # Log simple debug metrics
        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))
        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))
        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))

        # Train model
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)
        model.fit(Xp_train, yp_train)

        # Evaluate
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

        mlflow.log_metric("accuracy", float(acc))
        mlflow.log_metric("precision_macro", float(prec))
        mlflow.log_metric("recall_macro", float(rec))
        mlflow.log_metric("f1_macro", float(f1))

        # Log model using mlflow (server will store it)
        mlflow.sklearn.log_model(model, "model")

        # Ensure local artifact dir exists
        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")
        os.makedirs(local_run_dir, exist_ok=True)

        # Save confusion matrix PNG
        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")
        mlflow.log_artifact(cm_path)

        # Build JSON-serializable debug info
        debug_info = {
            "run_id": run_id,
            "poison_fraction": to_py(poison_fraction),
            "n_poisoned_samples": int(np.size(poisoned_idx)),
            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],
            "stats_before": to_py(stats_before),
            "stats_after": to_py(stats_after),
            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}
        }

        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")
        with open(debug_path, "w") as f:
            json.dump(debug_info, f, indent=2)

        mlflow.log_artifact(debug_path)

        # Also save model.joblib locally and log it as artifact
        model_joblib = os.path.join(local_run_dir, "model.joblib")
        joblib.dump(model, model_joblib)
        mlflow.log_artifact(model_joblib)

        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cd ~/iris_dvc_pipeline_mlops/week8 

cat > iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()    n = Xp.shape[0]    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)[7m        mlflow.sklearn.log_model(model, "model")[27m[7m        # Ensure local artifact dir exists[27m[7m        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")[27m[7m        os.makedirs(local_run_dir, exist_ok=True)[27m[7m        # Save confusion matrix PNG[27m[7m        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")[27m[7m        mlflow.log_artifact(cm_path)[27m[7m        # Build JSON-serializable debug info[27m[7m        debug_info = {[27m[7m            "run_id": run_id,[27m[7m            "poison_fraction": to_py(poison_fraction),[27m[7m            "n_poisoned_samples": int(np.size(poisoned_idx)),[27m[7m            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],[27m[7m            "stats_before": to_py(stats_before),[27m[7m            "stats_after": to_py(stats_after),[27m[7m            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1[27m[7m_macro": to_py(f1)}[27m[7m        }[27m[7m        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")[27m[7m        with open(debug_path, "w") as f:[27m[7m            json.dump(debug_info, f, indent=2)[27m[7m        mlflow.log_artifact(debug_path)[27m[7m        # Also save model.joblib locally and log it as artifact[27m[7m        model_joblib = os.path.join(local_run_dir, "model.joblib")[27m[7m        joblib.dump(model, model_joblib)[27m[7m        mlflow.log_artifact(model_joblib)[27m[7m        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")[27m[7mPY[27m[7mchmod +x iris_poisoning_mlflow_debug.py[27m        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PYchmod +x iris_poisoning_mlflow_debug.py
[?2004l[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ chmod +x iris_poisoning_mlflow_debug.py[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat > iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PY[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cd ~/iris_dvc[9P_pipeline_mlops/week8
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat > iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PY[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cd ~/iris_dvc[9P_pipeline_mlops/week8
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat iris_poisoning_mlflow_debug.py [A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cd ~/iris_dvc[1P_pipeline_mlops/week8[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat iris_poisoning_mlflow_debug.py [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Ccat iris_poi[1@s[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [C[C

[?2004lbash: ccat: command not found
[?2004h(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ ccat iris_poisoning_mlflow_debug.py [A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Chmod +x iris_poisoning_mlflow_debug.py[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat > iris_poisoning_mlflow_debug.py <<'PY'
#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))    poisoned_idx = []    if k > 0:        poisoned_idx = rng.choice(n, k, replace=False)        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)        Xp[poisoned_idx] += noise    # return poisoned_idx as numpy array or list â€” we'll normalize later    return Xp, y, poisoned_idxdef plot_and_save_cm(y_true, y_pred, outdir, label):    cm = confusion_matrix(y_true, y_pred)    fig, ax = plt.subplots(figsize=(4,3))    im = ax.imshow(cm, interpolation='nearest')    for i in range(cm.shape[0]):        for j in range(cm.shape[1]):            ax.text(j, i, int(cm[i, j]), ha="center", va="center")    ax.set_title(f"Confusion Matrix: {label}")    ax.set_xlabel("Predicted")    ax.set_ylabel("True")    plt.tight_layout()    outpath = os.path.join(outdir, f"confusion_{label}.png")    fig.savefig(outpath)    plt.close(fig)    return outpathdef to_py(x):    """Convert numpy types/arrays to native Python types for JSON serialization."""    if isinstance(x, np.ndarray):        return x.tolist()    if isinstance(x, (np.floating, np.integer)):        return x.item()    if isinstance(x, (list, tuple)):        return [to_py(i) for i in x]    if isinstance(x, dict):        return {k: to_py(v) for k, v in x.items()}    return xdef run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):    mlflow.set_experiment(experiment_name)    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"    with mlflow.start_run(run_name=run_name) as run:        run_id = run.info.run_id        # Log params        mlflow.log_param("poison_fraction", poison_fraction)        mlflow.log_param("noise_std", noise_std)        mlflow.log_param("seed", seed)        mlflow.log_param("n_estimators", n_estimators)        # Load data and split        iris = load_iris()        X, y = iris.data, iris.target        X_train, X_test, y_train, y_test = train_test_split(            X, y, test_size=0.2, random_state=seed, stratify=y        )        # stats before        stats_before = {            "mean": to_py(X_train.mean(axis=0)),            "std": to_py(X_train.std(axis=0)),            "shape": X_train.shape        }        # poison training set        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)        # stats after        stats_after = {            "mean": to_py(Xp_train.mean(axis=0)),            "std": to_py(Xp_train.std(axis=0)),            "shape": Xp_train.shape        }        # Log simple debug metrics        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))        # Train model        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)        model.fit(Xp_train, yp_train)        # Evaluate        y_pred = model.predict(X_test)        acc = accuracy_score(y_test, y_pred)        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)        mlflow.log_metric("accuracy", float(acc))        mlflow.log_metric("precision_macro", float(prec))        mlflow.log_metric("recall_macro", float(rec))        mlflow.log_metric("f1_macro", float(f1))        # Log model using mlflow (server will store it)        mlflow.sklearn.log_model(model, "model")        # Ensure local artifact dir exists        local_run_dir = os.path.join("mlruns", run.info.experiment_id, run_id, "artifacts")        os.makedirs(local_run_dir, exist_ok=True)        # Save confusion matrix PNG        cm_path = plot_and_save_cm(y_test, y_pred, local_run_dir, f"{int(poison_fraction*100)}pct")        mlflow.log_artifact(cm_path)        # Build JSON-serializable debug info        debug_info = {            "run_id": run_id,            "poison_fraction": to_py(poison_fraction),            "n_poisoned_samples": int(np.size(poisoned_idx)),            "poisoned_indices_sample": to_py(poisoned_idx)[:50] if poisoned_idx is not None else [],            "stats_before": to_py(stats_before),            "stats_after": to_py(stats_after),            "metrics": {"accuracy": to_py(acc), "precision_macro": to_py(prec), "recall_macro": to_py(rec), "f1_macro": to_py(f1)}        }        debug_path = os.path.join(local_run_dir, f"debug_{int(poison_fraction*100)}pct.json")        with open(debug_path, "w") as f:            json.dump(debug_info, f, indent=2)        mlflow.log_artifact(debug_path)        # Also save model.joblib locally and log it as artifact        model_joblib = os.path.join(local_run_dir, "model.joblib")        joblib.dump(model, model_joblib)        mlflow.log_artifact(model_joblib)        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")PY[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cd ~/iris_dvc[9P_pipeline_mlops/week8
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K
[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(venv) (base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat iris_poisoning_mlflow_debug.py 
[?2004l#!/usr/bin/env python3
"""
Fixed iris_poisoning_mlflow_debug.py
Ensures JSON-serializable debug info by converting numpy arrays to lists.
"""
import os
import json
import argparse
import numpy as np
import joblib
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

import mlflow
import mlflow.sklearn
from mlflow.tracking import MlflowClient

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

def ensure_tracking_uri():
    uri = os.environ.get("MLFLOW_TRACKING_URI")
    if uri:
        mlflow.set_tracking_uri(uri)
    else:
        default = "http://127.0.0.1:5000"
        os.environ["MLFLOW_TRACKING_URI"] = default
        mlflow.set_tracking_uri(default)
    return mlflow.get_tracking_uri()

def poison_data_debug(X, y, poison_fraction, noise_std=1.0, seed=None):
    rng = np.random.RandomState(seed)
    Xp = X.copy()
    n = Xp.shape[0]
    k = int(round(n * poison_fraction))
    poisoned_idx = []
    if k > 0:
        poisoned_idx = rng.choice(n, k, replace=False)
        noise = rng.normal(loc=0.0, scale=noise_std, size=Xp[poisoned_idx].shape)
        Xp[poisoned_idx] += noise
    # return poisoned_idx as numpy array or list â€” we'll normalize later
    return Xp, y, poisoned_idx

def plot_and_save_cm(y_true, y_pred, outdir, label):
    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(4,3))
    im = ax.imshow(cm, interpolation='nearest')
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, int(cm[i, j]), ha="center", va="center")
    ax.set_title(f"Confusion Matrix: {label}")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("True")
    plt.tight_layout()
    outpath = os.path.join(outdir, f"confusion_{label}.png")
    fig.savefig(outpath)
    plt.close(fig)
    return outpath

def to_py(x):
    """Convert numpy types/arrays to native Python types for JSON serialization."""
    if isinstance(x, np.ndarray):
        return x.tolist()
    if isinstance(x, (np.floating, np.integer)):
        return x.item()
    if isinstance(x, (list, tuple)):
        return [to_py(i) for i in x]
    if isinstance(x, dict):
        return {k: to_py(v) for k, v in x.items()}
    return x

def run_experiment(poison_fraction, seed=42, noise_std=1.0, n_estimators=200, experiment_name="iris_poisoning_experiment_debug"):
    mlflow.set_experiment(experiment_name)
    run_name = f"poison_{int(poison_fraction*100)}pct_seed{seed}"
    with mlflow.start_run(run_name=run_name) as run:
        run_id = run.info.run_id
        # Log params
        mlflow.log_param("poison_fraction", poison_fraction)
        mlflow.log_param("noise_std", noise_std)
        mlflow.log_param("seed", seed)
        mlflow.log_param("n_estimators", n_estimators)

        # Load data and split
        iris = load_iris()
        X, y = iris.data, iris.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=seed, stratify=y
        )

        # stats before
        stats_before = {
            "mean": to_py(X_train.mean(axis=0)),
            "std": to_py(X_train.std(axis=0)),
            "shape": X_train.shape
        }

        # poison training set
        Xp_train, yp_train, poisoned_idx = poison_data_debug(X_train, y_train, poison_fraction, noise_std=noise_std, seed=seed)

        # stats after
        stats_after = {
            "mean": to_py(Xp_train.mean(axis=0)),
            "std": to_py(Xp_train.std(axis=0)),
            "shape": Xp_train.shape
        }

        # Log simple debug metrics
        mlflow.log_metric("n_poisoned_samples", int(np.size(poisoned_idx)))
        mlflow.log_metric("train_mean_feature0_before", float(stats_before["mean"][0]))
        mlflow.log_metric("train_mean_feature0_after", float(stats_after["mean"][0]))

        # Train model
        model = RandomForestClassifier(n_estimators=n_estimators, random_state=seed)
        model.fit(Xp_train, yp_train)

        # Evaluate
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
        rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)

  Script started on 2025-11-16 13:07:54+00:00 [TERM="xterm-256color" TTY="/dev/pts/5" COLUMNS="111" LINES="39"]
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ cat iris_poisoning_mlflow_debug.py [A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Ccat iris_poisoning_[1@m[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Chmod +x iris_poisoning_mlflow_debug.py[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ PY[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C        print(f"[run {run_id}] poison={poison_fraction} n_poisoned={int(np.size(poisoned_idx))} acc={acc:.4f}")[APY[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cchmod +x iris_poisoning_mlflow_debug.py[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Ccat iris_poisoning_[3Pmlflow_debug.py [A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [Cat iris_poisoning_m[1P[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[7mpython iris_poisoni[27m[7mn[27m[7mg_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python iris_poisoning_mlflow_debug.py --poison-levels 0.0 0.05 0.10 0.50 --noise-std 1.0
[?2004lUsing MLflow tracking URI: http://127.0.0.1:5000
2025/11/16 13:08:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 13:08:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[run 687da2e845b34abab292728b9be852fd] poison=0.0 n_poisoned=0 acc=0.9000
ğŸƒ View run at: http://127.0.0.1:5000/#/experiments/1/runs/687da2e845b34abab292728b9be852fd
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
ğŸƒ View run poison_0pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/687da2e845b34abab292728b9be852fd
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
2025/11/16 13:08:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 13:08:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[run 66bc634eefd345509d792b61bbe650ac] poison=0.05 n_poisoned=6 acc=0.9333
ğŸƒ View run at: http://127.0.0.1:5000/#/experiments/1/runs/66bc634eefd345509d792b61bbe650ac
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
ğŸƒ View run poison_5pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/66bc634eefd345509d792b61bbe650ac
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
2025/11/16 13:08:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 13:08:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[run a54982e206ad45bf9811e4925aa23f18] poison=0.1 n_poisoned=12 acc=0.9667
ğŸƒ View run at: http://127.0.0.1:5000/#/experiments/1/runs/a54982e206ad45bf9811e4925aa23f18
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
ğŸƒ View run poison_10pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/a54982e206ad45bf9811e4925aa23f18
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
2025/11/16 13:08:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.
[31m2025/11/16 13:08:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.[0m
[run 00e57b74699848dfaaf371b893b17385] poison=0.5 n_poisoned=60 acc=0.9333
ğŸƒ View run at: http://127.0.0.1:5000/#/experiments/1/runs/00e57b74699848dfaaf371b893b17385
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
ğŸƒ View run poison_50pct_seed42 at: http://127.0.0.1:5000/#/experiments/1/runs/00e57b74699848dfaaf371b893b17385
ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/1
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7m# list experiments [27m[7ma[27m[7mnd runs quickly [27m
[7mpython - <<'PY'[27m
[7mimport os[27m
[7mfrom mlflow.tracking import MlflowClient[27m
[7mos.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"[27m
[7mc=MlflowClient()[27m
[7mfor e in c.list_experiments():[27m
[7m    print("EXP:", e.experiment_id, e.name)[27m
[7m    runs = c.search_runs(e.experiment_id, "")[27m
[7m    for r in runs:[27m
[7m        print(" ", r.info.run_id, r.info.run_name, {k:v for k,v in r.data.metrics.items()})[27m
[7mPY[27m
[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C# list experiments and runs quickly
python - <<'PY'
import os
from mlflow.tracking import MlflowClient
os.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"
c=MlflowClient()
for e in c.list_experiments():
    print("EXP:", e.experiment_id, e.name)
    runs = c.search_runs(e.experiment_id, "")
    for r in runs:
        print(" ", r.info.run_id, r.info.run_name, {k:v for k,v in r.data.metrics.items()})
PY
[A
[?2004lTraceback (most recent call last):
  File "<stdin>", line 5, in <module>
AttributeError: 'MlflowClient' object has no attribute 'list_experiments'. Did you mean: 'get_experiment'?
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython - <<'PY'[27m
[7mimport os[27m
[7mfrom mlflow.tracking import MlflowClient[27m
[7mos.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"[27m
[7mc=MlflowClient()[27m
[7mfor e in c.list_experiments():[27m
[7m    print("EXP:", e.experiment_id, e.name)[27m
[7m    runs = c.search_runs(e.experiment_id, "")[27m
[7m    for r in runs:[27m
[7m        print(" ", r.info.run_id, r.info.run_name, {k:v for k,v in r.data.metrics.items()})[27m
[7mPY[27m[A[A[A[A[A[A[A[A[A[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ python - <<'PY'
import os
from mlflow.tracking import MlflowClient
os.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"
c=MlflowClient()
for e in c.list_experiments():
    print("EXP:", e.experiment_id, e.name)
    runs = c.search_runs(e.experiment_id, "")
    for r in runs:
        print(" ", r.info.run_id, r.info.run_name, {k:v for k,v in r.data.metrics.items()})
PY
[?2004lTraceback (most recent call last):
  File "<stdin>", line 5, in <module>
AttributeError: 'MlflowClient' object has no attribute 'list_experiments'. Did you mean: 'get_experiment'?
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython - <<'PY'[27m
[7mimport os[27m
[7mfrom mlflow.tracking import MlflowClient[27m

[7mos.environ["MLFLOW_TRACKING_URI"] = "http://127.0.0.1:5000"[27m

[7mclient = MlflowClient()[27m

[7m# Get all experiments[27m
[7mexperiments = client.search_experiments()[27m

[7mfor e in experiments:[27m
[7m    print(f"EXP: {e.experiment_id} {e.name}")[27m

[7m    # Get all runs in this experiment[27m
[7m    runs = client.search_runs([e.experiment_id])[27m

[7m    for r in runs:[27m
[7m        metrics = {k: v for k, v in r.data.metrics.items()}[27m
[7m        print("  ", r.info.run_id, r.info.run_name, metrics)[27m
[7mPY[27m
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython - <<'PY'
import os
from mlflow.tracking import MlflowClient

os.environ["MLFLOW_TRACKING_URI"] = "http://127.0.0.1:5000"

client = MlflowClient()

# Get all experiments
experiments = client.search_experiments()

for e in experiments:
    print(f"EXP: {e.experiment_id} {e.name}")

    # Get all runs in this experiment
    runs = client.search_runs([e.experiment_id])

    for r in runs:
        metrics = {k: v for k, v in r.data.metrics.items()}
        print("  ", r.info.run_id, r.info.run_name, metrics)
PY
[A
[?2004lEXP: 1 iris_poisoning_experiment_debug
   00e57b74699848dfaaf371b893b17385 poison_50pct_seed42 {'n_poisoned_samples': 60.0, 'train_mean_feature0_before': 5.841666666666668, 'train_mean_feature0_after': 5.847568110211581, 'accuracy': 0.9333333333333333, 'precision_macro': 0.9444444444444445, 'recall_macro': 0.9333333333333332, 'f1_macro': 0.9326599326599326}
   a54982e206ad45bf9811e4925aa23f18 poison_10pct_seed42 {'n_poisoned_samples': 12.0, 'train_mean_feature0_before': 5.841666666666668, 'train_mean_feature0_after': 5.812731348851177, 'accuracy': 0.9666666666666667, 'precision_macro': 0.9696969696969697, 'recall_macro': 0.9666666666666667, 'f1_macro': 0.9665831244778612}
   66bc634eefd345509d792b61bbe650ac poison_5pct_seed42 {'n_poisoned_samples': 6.0, 'train_mean_feature0_before': 5.841666666666668, 'train_mean_feature0_after': 5.840891592629186, 'accuracy': 0.9333333333333333, 'precision_macro': 0.9333333333333332, 'recall_macro': 0.9333333333333332, 'f1_macro': 0.9333333333333332}
   687da2e845b34abab292728b9be852fd poison_0pct_seed42 {'n_poisoned_samples': 0.0, 'train_mean_feature0_before': 5.841666666666668, 'train_mean_feature0_after': 5.841666666666668, 'accuracy': 0.9, 'precision_macro': 0.9023569023569024, 'recall_macro': 0.9, 'f1_macro': 0.899749373433584}
EXP: 0 Default
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mpython - <<'PY'[27m
[7mimport os, csv[27m
[7mfrom mlflow.tracking import MlflowClient[27m
[7mos.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"[27m
[7mclient = MlflowClient()[27m
[7mexp = client.get_experiment_by_name("iris_poisoning_experiment_debug") or client.get_experiment_by_name("iris_p[27m[7mo[27m[7misoning_experiment") [27m
[7mif exp is None:[27m
[7m    raise SystemExit("Experiment not found")[27m
[7mruns = client.search_runs(exp.experiment_id, "")[27m
[7mrows=[][27m
[7mfor r in runs:[27m
[7m    rows.append({[27m
[7m        "run_id": r.info.run_id,[27m
[7m        "run_name": r.info.run_name,[27m
[7m        "poison_fraction": r.data.params.get("poison_fraction"),[27m
[7m        "n_poisoned_samples": r.data.metrics.get("n_poisoned_samples"),[27m
[7m        "accuracy": r.data.metrics.get("accuracy"),[27m
[7m        "precision_macro": r.data.metrics.get("precision_macro"),[27m
[7m        "recall_macro": r.data.metrics.get("recall_macro"),[27m
[7m        "f1_macro": r.data.metrics.get("f1_macro"),[27m
[7m    })[27m
[7mkeys = rows[0].keys() if rows else [][27m
[7mwith open("week8_metrics.csv","w",newline="") as f:[27m
[7m    writer=csv.DictWriter(f, keys)[27m
[7m    writer.writeheader()[27m
[7m    writer.writerows(rows)[27m
[7mprint("Created week8_metrics.csv with", len(rows), "rows")[27m
[7mPY[27m
[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cpython - <<'PY'
import os, csv
from mlflow.tracking import MlflowClient
os.environ["MLFLOW_TRACKING_URI"]="http://127.0.0.1:5000"
client = MlflowClient()
exp = client.get_experiment_by_name("iris_poisoning_experiment_debug") or client.get_experiment_by_name("iris_poisoning_experiment")
if exp is None:
    raise SystemExit("Experiment not found")
runs = client.search_runs(exp.experiment_id, "")
rows=[]
for r in runs:
    rows.append({
        "run_id": r.info.run_id,
        "run_name": r.info.run_name,
        "poison_fraction": r.data.params.get("poison_fraction"),
        "n_poisoned_samples": r.data.metrics.get("n_poisoned_samples"),
        "accuracy": r.data.metrics.get("accuracy"),
        "precision_macro": r.data.metrics.get("precision_macro"),
        "recall_macro": r.data.metrics.get("recall_macro"),
        "f1_macro": r.data.metrics.get("f1_macro"),
    })
keys = rows[0].keys() if rows else []
with open("week8_metrics.csv","w",newline="") as f:
    writer=csv.DictWriter(f, keys)
    writer.writeheader()
    writer.writerows(rows)
print("Created week8_metrics.csv with", len(rows), "rows")
PY
[A
[?2004lCreated week8_metrics.csv with 4 rows
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mhead -n 30 week8_me[27m[7mt[27m[7mrics.csv [27m
[A[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Chead -n 30 week8_metrics.csv
[A
[?2004lrun_id,run_name,poison_fraction,n_poisoned_samples,accuracy,precision_macro,recall_macro,f1_macro
00e57b74699848dfaaf371b893b17385,poison_50pct_seed42,0.5,60.0,0.9333333333333333,0.9444444444444445,0.9333333333333332,0.9326599326599326
a54982e206ad45bf9811e4925aa23f18,poison_10pct_seed42,0.1,12.0,0.9666666666666667,0.9696969696969697,0.9666666666666667,0.9665831244778612
66bc634eefd345509d792b61bbe650ac,poison_5pct_seed42,0.05,6.0,0.9333333333333333,0.9333333333333332,0.9333333333333332,0.9333333333333332
687da2e845b34abab292728b9be852fd,poison_0pct_seed42,0.0,0.0,0.9,0.9023569023569024,0.9,0.899749373433584
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [?2004l
exit

Script done on 2025-11-16 13:10:47+00:00 [COMMAND_EXIT_CODE="0"]
Script started on 2025-11-16 13:11:27+00:00 [TERM="xterm-256color" TTY="/dev/pts/5" COLUMNS="111" LINES="39"]
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mmkdir -p artifacts_[27m[7mf[27m[7mlat[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ mkdir -p artifacts_flat
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mmkdir -p artifacts_[27m[7mf[27m[7mlat[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ mkdir -p artifacts_f[1Pla[K[K[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K
[K[A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[K[7mfind mlruns -type f[27m[7m [27m[7m\( -name "confusion_*.png" -o -name "debug_*.json" -o -name "model.joblib" \) -exec cp {} artifacts_flat/ \;[27m[Afind mlruns -type f \( -name "confusion_*.png" -o -name "debug_*.json" -o -name "model.joblib" \) -exec cp {} artifacts_flat/ \;
[?2004l[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [7mls -lah artifacts_f[27m[7ml[27m[7mat | sed -n '1,200p'[27m[A(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ ls -lah artifacts_flat | sed -n '1,200p'
[?2004ltotal 252K
drwxr-xr-x 2 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 13:12 .
drwxr-xr-x 7 satishsharma1911_gmail_com satishsharma1911_gmail_com 4.0K Nov 16 13:11 ..
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  13K Nov 16 13:12 confusion_0pct.png
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  13K Nov 16 13:12 confusion_10pct.png
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  13K Nov 16 13:12 confusion_50pct.png
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  13K Nov 16 13:12 confusion_5pct.png
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  898 Nov 16 13:12 debug_0pct.json
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com 1.1K Nov 16 13:12 debug_10pct.json
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com 1.4K Nov 16 13:12 debug_50pct.json
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com  980 Nov 16 13:12 debug_5pct.json
-rw-r--r-- 1 satishsharma1911_gmail_com satishsharma1911_gmail_com 164K Nov 16 13:12 model.joblib
[?2004h(base) ]0;satishsharma1911_gmail_com@instance-20251031-150440: ~/iris_dvc_pipeline_mlops/week8[01;32msatishsharma1911_gmail_com@instance-20251031-150440[00m:[01;34m~/iris_dvc_pipeline_mlops/week8[00m$ [?2004l
exit

Script done on 2025-11-16 13:13:07+00:00 [COMMAND_EXIT_CODE="0"]
